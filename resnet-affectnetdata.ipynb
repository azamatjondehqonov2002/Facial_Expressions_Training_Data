{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U tensorflow-addons","metadata":{"id":"QZUVZ_MAC_DR","outputId":"58bbecad-6329-429a-d107-6e0a783f98e7","execution":{"iopub.status.busy":"2023-05-01T03:09:31.163712Z","iopub.execute_input":"2023-05-01T03:09:31.164746Z","iopub.status.idle":"2023-05-01T03:09:41.905177Z","shell.execute_reply.started":"2023-05-01T03:09:31.164699Z","shell.execute_reply":"2023-05-01T03:09:41.903964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt  # plot\nimport random","metadata":{"id":"aoCZGHGvDf8-","execution":{"iopub.status.busy":"2023-05-01T03:09:41.907777Z","iopub.execute_input":"2023-05-01T03:09:41.908667Z","iopub.status.idle":"2023-05-01T03:09:49.044239Z","shell.execute_reply.started":"2023-05-01T03:09:41.908609Z","shell.execute_reply":"2023-05-01T03:09:49.043129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mounted Drive**","metadata":{"id":"6iKw86laDhsM"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"P8MKjVRyDizf","outputId":"567fb5e8-10ca-467f-e214-ed5f8077bbec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GetData**","metadata":{"id":"bt4QHpkhDz6R"}},{"cell_type":"code","source":"# !unzip /content/drive/MyDrive/Exp/archive.zip -d /content/","metadata":{"id":"hPaeaJchD01P","outputId":"ef061587-aad7-481b-c413-b9fed182e774"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndef countFile(link):\n    path = link\n    num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n\n    print(f\"Number of files in directory {link} is \", num_files)","metadata":{"id":"yA5Qbv76EVsN","execution":{"iopub.status.busy":"2023-05-01T03:11:08.449353Z","iopub.execute_input":"2023-05-01T03:11:08.449714Z","iopub.status.idle":"2023-05-01T03:11:08.456164Z","shell.execute_reply.started":"2023-05-01T03:11:08.449681Z","shell.execute_reply":"2023-05-01T03:11:08.454925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countFile(\"/kaggle/input/affectnet-training-data/happy\")\ncountFile(\"/kaggle/input/affectnet-training-data/sad\")","metadata":{"id":"1spoKTDRE6cG","outputId":"0e442810-13b9-4fa5-a43f-f2b2c4ee4753","execution":{"iopub.status.busy":"2023-05-01T03:11:10.526364Z","iopub.execute_input":"2023-05-01T03:11:10.526747Z","iopub.status.idle":"2023-05-01T03:11:14.274326Z","shell.execute_reply.started":"2023-05-01T03:11:10.526710Z","shell.execute_reply":"2023-05-01T03:11:14.273344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Construct dataset**","metadata":{"id":"KuaqBEQjFXC6"}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom keras.utils import to_categorical\nimport os\nimport pandas as pd","metadata":{"id":"wf8j2uavFYne","execution":{"iopub.status.busy":"2023-05-01T03:11:45.563857Z","iopub.execute_input":"2023-05-01T03:11:45.564571Z","iopub.status.idle":"2023-05-01T03:11:45.721427Z","shell.execute_reply.started":"2023-05-01T03:11:45.564530Z","shell.execute_reply":"2023-05-01T03:11:45.720431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df = pd.read_csv(\"/content/labels.csv\")","metadata":{"id":"6qTSbAabOo_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#happy_link = ['/content/' + ele for ele in df[df['label'] == 'happy']['pth'].to_list() if 'happy' in ele]","metadata":{"id":"Zb4mrduXOvdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sad_link = ['/content/' + ele for ele in df[df['label'] == 'sad']['pth'].to_list() if 'sad' in ele]","metadata":{"id":"YYclojIeO6SG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_PATH = '/kaggle/input/affectnet-training-data/'\nEMOTIONS = [\"happy\",\"sad\"]\nIMAGE_SIZE = (96, 96)\n\ndef image_generator(input_path, emotions, image_size):\n    for index, emotion in enumerate(emotions):\n        for filename in os.listdir(os.path.join(input_path, emotion)):\n            img = cv2.imread(os.path.join(input_path, emotion, filename))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n            #img = cv2.resize(img, image_size)\n            #img = img.astype('float32') / 255.0  # Normilize\n            yield img, index\n\ndef load_images(input_path, emotions, image_size):\n    X, y = [], []\n    for img, label in image_generator(input_path, emotions, image_size):\n        X.append(img)\n        y.append(label)\n    X = np.array(X)\n    y = np.array(y)\n    return X, y","metadata":{"id":"t-Jl6K9zGlsK","execution":{"iopub.status.busy":"2023-05-01T03:13:05.562550Z","iopub.execute_input":"2023-05-01T03:13:05.563176Z","iopub.status.idle":"2023-05-01T03:13:05.570736Z","shell.execute_reply.started":"2023-05-01T03:13:05.563114Z","shell.execute_reply":"2023-05-01T03:13:05.569708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = load_images(INPUT_PATH,EMOTIONS, IMAGE_SIZE)\ninput_shape = X[0].shape","metadata":{"id":"L5ewqtgSG-6k","execution":{"iopub.status.busy":"2023-05-01T03:13:08.841727Z","iopub.execute_input":"2023-05-01T03:13:08.842235Z","iopub.status.idle":"2023-05-01T03:14:17.598060Z","shell.execute_reply.started":"2023-05-01T03:13:08.842189Z","shell.execute_reply":"2023-05-01T03:14:17.596971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.random.randint(len(X))\n\n# display the image and its corresponding label from arrays\nplt.imshow(X[idx])\nplt.title(EMOTIONS[np.argmax(y[idx])])\nplt.axis('off')  # remove the grid\nplt.show()","metadata":{"id":"a_EKre0NHMNF","outputId":"61897c41-4a3b-4a0b-9a10-413dc36eaff7","execution":{"iopub.status.busy":"2023-05-01T03:18:30.246853Z","iopub.execute_input":"2023-05-01T03:18:30.247272Z","iopub.status.idle":"2023-05-01T03:18:30.348824Z","shell.execute_reply.started":"2023-05-01T03:18:30.247232Z","shell.execute_reply":"2023-05-01T03:18:30.347519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Util Function**","metadata":{"id":"CnTmpn-gKxjT"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Lambda, Dropout, LayerNormalization, MultiHeadAttention\nfrom tensorflow.keras.activations import gelu\nimport numpy as np\n\n#Patch image to subimage (adapt with input of visionTransformer)\nclass Patches(layers.Layer):\n    def __init__(self,patch_size):\n        super(Patches,self).__init__()\n        self.patch_size = patch_size\n    \n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images = images,\n            sizes = [1,self.patch_size,self.patch_size,1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size,-1,patch_dims])\n        # print(\"hehe:, \",patches.shape)\n        return patches\n        \ndef get_angle(pos, i, d_model):\n    indices = i // 2\n    angle_rates = 1 / np.power(10000,(2*indices) / np.float32(d_model))\n    \n    return pos * angle_rates\n    \ndef pos_encoding(pos,d_model):\n    angle_rads = get_angle(np.arange(pos)[:,np.newaxis],\n                            np.arange(d_model)[np.newaxis,:],\n                            d_model)\n    \n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    return tf.cast(angle_rads, dtype=tf.float32)\n\nclass PatchEncoder(layers.Layer):\n    def __init__(self, num_patches, projection_dim):\n        super(PatchEncoder,self).__init__()\n        self.num_patches = num_patches\n        self.projection_dim = projection_dim\n        self.projection = layers.Dense(units=projection_dim)\n        self.position_embedding = pos_encoding(pos = num_patches, d_model = projection_dim)\n\n    def call(self, patch):\n        length = tf.shape(patch)[1]\n        # print(\"debug1 \",self.projection(patch).shape)\n        # print(\"debug2 \",self.position_embedding.shape)\n        encoded = self.projection(patch) + self.position_embedding\n        return encoded\n\nclass RandomSampling(layers.Layer):\n    def __init__(self, num_patches, mask_ratio=0.75):\n        super(RandomSampling,self).__init__()\n        self.num_patches = num_patches\n        self.mask_ratio = mask_ratio\n        \n        self.num_mask = int(mask_ratio * num_patches)\n        self.un_masked_indices = None\n        self.masked_indices = None\n    \n    def get_indices(self):\n        return [self.masked_indices, self.un_masked_indices]\n    \n    def call(self, patches):\n        self.masked_indices = np.random.choice(self.num_patches, size=self.num_mask, replace=False)\n        self.un_masked_indices = np.delete(np.array(range(self.num_patches)), self.masked_indices)\n        \n        return tf.gather(patches, self.un_masked_indices, axis=1), self.masked_indices, self.un_masked_indices\n\nclass MaskToken(layers.Layer):\n    def __init__(self):\n        super(MaskToken,self).__init__()\n        self.mask_indices = None\n        self.un_masked_indices = None\n        self.indices = None\n        self.mst = None\n        self.hidden_size = None\n    \n    def build(self, input_shape):\n        self.hidden_size = input_shape[-1]\n        self.mst = tf.Variable(\n            name=\"mst\",\n            initial_value = tf.random.normal(\n                shape=(1, 1, self.hidden_size), dtype='float32'), \n            trainable=True\n        )\n\n    def call(self, inputs, mask_indices, un_masked_indices):\n        self.mask_indices = mask_indices\n        self.un_masked_indices = un_masked_indices\n                \n        batch_size = tf.shape(inputs)[0]\n        mask_num = self.mask_indices.shape[0]\n        #update for bach_size\n        mst_broadcasted = tf.cast(\n                            tf.broadcast_to(self.mst, [batch_size, mask_num, self.hidden_size]),\n                            dtype=inputs.dtype,\n                        )\n        self.indices = tf.concat([self.mask_indices, self.un_masked_indices], axis=0)\n        updates = tf.concat([mst_broadcasted, inputs], axis=1)\n        out = tf.gather(updates, self.indices, axis=1, batch_dims=0)\n        return out\n\nclass TransformerBlock(layers.Layer):\n    def __init__(self, num_heads, mlp_dim, dropout):\n        super(TransformerBlock,self).__init__()\n        self.num_heads = num_heads\n        self.mlp_dim = mlp_dim\n        self.dropout = dropout\n\n    def build(self, input_shape):\n        self.att = MultiHeadAttention(\n            num_heads = self.num_heads,\n            key_dim = input_shape[-1] // self.num_heads #d_model is input_shape[-1]\n        )\n        \n        self.mlpBlock = Sequential([\n            Dense(self.mlp_dim,activation=\"linear\"),\n            Lambda(lambda x : gelu(x, approximate=False)),\n            Dropout(self.dropout),\n            Dense(input_shape[-1]),\n            Dropout(self.dropout),\n        ])\n        \n        self.layerNorm1 = LayerNormalization(epsilon = 1e-6)\n        self.layerNorm2 = LayerNormalization(epsilon = 1e-6)\n        self.layerDropout = Dropout(self.dropout)\n    \n    def call(self, inputs, training):\n        x = self.att(inputs,inputs)\n        x = self.layerDropout(x, training = training)\n        x = x + inputs\n        y = self.layerNorm2(x)\n        y = self.mlpBlock(y)\n        x = x + y\n        x = self.layerNorm1(x)\n        return x\n\ndef mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = layers.Dense(units = units, activation=tf.nn.gelu)(x)\n        x = layers.Dropout(dropout_rate)(x)\n    return x","metadata":{"id":"DFHfLXOuKzlT","execution":{"iopub.status.busy":"2023-05-01T03:19:37.182769Z","iopub.execute_input":"2023-05-01T03:19:37.183128Z","iopub.status.idle":"2023-05-01T03:19:37.212982Z","shell.execute_reply.started":"2023-05-01T03:19:37.183094Z","shell.execute_reply":"2023-05-01T03:19:37.211917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**train, val, test split**","metadata":{"id":"D54VUlQcIpjz"}},{"cell_type":"code","source":"id_pos = np.where(y == 1)[0]\nid_neg = np.where(y == 0)[0]\n\nnp.random.shuffle(id_pos)\nnp.random.shuffle(id_neg)\n\nid_train_neg = id_neg[:int(len(id_neg) * 0.7)]\nid_train_pos = id_pos[:int(len(id_pos) * 0.7)]\nid_train = np.concatenate((id_train_neg, id_train_pos), axis = 0)\n\nid_val_neg = id_neg[int(len(id_neg) * 0.7):int(len(id_neg) * 0.9)]\nid_val_pos = id_pos[int(len(id_pos) * 0.7):int(len(id_pos) * 0.9)]\nid_val = np.concatenate((id_val_neg, id_val_pos), axis = 0)\n\nid_test_neg = id_neg[int(len(id_neg) * 0.9):]\nid_test_pos = id_pos[int(len(id_pos) * 0.9):]\nid_test = np.concatenate((id_test_neg, id_test_pos), axis = 0)","metadata":{"id":"d5U_T1N3IsMy","execution":{"iopub.status.busy":"2023-05-01T03:23:33.866028Z","iopub.execute_input":"2023-05-01T03:23:33.866645Z","iopub.status.idle":"2023-05-01T03:23:33.877231Z","shell.execute_reply.started":"2023-05-01T03:23:33.866604Z","shell.execute_reply":"2023-05-01T03:23:33.875318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train\nx_train = X[id_train]\ny_train = y[id_train]\n#val\nx_val = X[id_val]\ny_val = y[id_val]\n#test\nx_test = X[id_test]\ny_test = y[id_test]\n\ny_train = y_train.reshape((-1, 1))\ny_val = y_val.reshape((-1, 1))\ny_test = y_test.reshape((-1, 1))\n\nprint(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\nprint(f\"x_val shape: {x_val.shape} - y_val shape: {y_val.shape}\")\nprint(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")","metadata":{"id":"D4bFIcsCI878","outputId":"d4ac4bb3-e379-4f24-d749-1546fb88e359","execution":{"iopub.status.busy":"2023-05-01T03:23:47.082419Z","iopub.execute_input":"2023-05-01T03:23:47.083017Z","iopub.status.idle":"2023-05-01T03:23:47.152498Z","shell.execute_reply.started":"2023-05-01T03:23:47.082978Z","shell.execute_reply":"2023-05-01T03:23:47.151323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(y_train,dtype = 'int32')\ny_val = to_categorical(y_val,dtype = 'int32')\ny_test = to_categorical(y_test,dtype = 'int32')","metadata":{"id":"O8BvlqRyTqJn","execution":{"iopub.status.busy":"2023-05-01T03:24:03.120044Z","iopub.execute_input":"2023-05-01T03:24:03.120969Z","iopub.status.idle":"2023-05-01T03:24:03.126829Z","shell.execute_reply.started":"2023-05-01T03:24:03.120928Z","shell.execute_reply":"2023-05-01T03:24:03.125751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"id":"uBGlfMMJTvsu","outputId":"17ff8d6f-1c61-481a-bc0a-8a16d7a45b2e","execution":{"iopub.status.busy":"2023-05-01T03:24:37.877185Z","iopub.execute_input":"2023-05-01T03:24:37.877559Z","iopub.status.idle":"2023-05-01T03:24:37.886216Z","shell.execute_reply.started":"2023-05-01T03:24:37.877524Z","shell.execute_reply":"2023-05-01T03:24:37.885173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hyperparam**","metadata":{"id":"mAOah7wZKlvA"}},{"cell_type":"code","source":"learning_rate = 0.001\nweight_decay = 0.0001\nbatch_size = 256\nnum_epochs = 100\nimage_size = 72  # We'll resize input images to this size\npatch_size = 6  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 64\nnum_heads = 4\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\ntransformer_layers = 8\nmlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\ndrop_out = 0.1\nnum_class = 2","metadata":{"id":"ssM9_FvnKne7","execution":{"iopub.status.busy":"2023-05-01T03:25:41.949389Z","iopub.execute_input":"2023-05-01T03:25:41.950007Z","iopub.status.idle":"2023-05-01T03:25:41.956568Z","shell.execute_reply.started":"2023-05-01T03:25:41.949966Z","shell.execute_reply":"2023-05-01T03:25:41.955388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Augmentation**","metadata":{"id":"lzNr6q5bKsdt"}},{"cell_type":"code","source":"data_augmentation = keras.Sequential(\n    [\n        layers.Normalization(),\n        layers.Resizing(image_size, image_size),\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(factor=0.02),\n        layers.RandomZoom(\n            height_factor=0.2, width_factor=0.2\n        ),\n    ],\n    name=\"data_augmentation\",\n)\n\ndata_augmentation.layers[0].adapt(x_train)","metadata":{"id":"yBPSJ9PCKtdW","execution":{"iopub.status.busy":"2023-05-01T03:25:58.537260Z","iopub.execute_input":"2023-05-01T03:25:58.537632Z","iopub.status.idle":"2023-05-01T03:26:02.326929Z","shell.execute_reply.started":"2023-05-01T03:25:58.537597Z","shell.execute_reply":"2023-05-01T03:26:02.325742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create model**","metadata":{"id":"elUuqmtpK2T8"}},{"cell_type":"code","source":"def vit_model():\n    inputs = layers.Input(input_shape)\n    augmented = data_augmentation(inputs)\n    patches = Patches(patch_size)(augmented)\n    x = PatchEncoder(num_patches,projection_dim)(patches)\n    for _ in range(transformer_layers):\n         x = TransformerBlock(num_heads=num_heads, mlp_dim=projection_dim * 2, dropout=drop_out) (x) \n    # print(x.shape)\n    x = layers.Flatten()(x)\n    x = layers.Dropout(0.2)(x)\n    # print(x.shape)\n    # Add MLP.\n    features = mlp(x, hidden_units=mlp_head_units, dropout_rate=0.2)\n    logits = layers.Dense(num_class, activation = \"softmax\")(features)\n    model = keras.Model(inputs=inputs, outputs=logits)\n    \n    return model","metadata":{"id":"TlO8Zwc8K3bm","execution":{"iopub.status.busy":"2023-05-01T03:26:10.713770Z","iopub.execute_input":"2023-05-01T03:26:10.714483Z","iopub.status.idle":"2023-05-01T03:26:10.721665Z","shell.execute_reply.started":"2023-05-01T03:26:10.714441Z","shell.execute_reply":"2023-05-01T03:26:10.720561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50\n\ndef resnet_model():\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n\n    x = base_model.output\n    x = layers.GlobalAveragePooling2D()(x)\n    \n    # output has shape of (None, 2)\n    output = layers.Dense(num_class, activation=\"softmax\")(x)\n    model = keras.Model(inputs=base_model.input, outputs=output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-01T03:36:24.584632Z","iopub.execute_input":"2023-05-01T03:36:24.585281Z","iopub.status.idle":"2023-05-01T03:36:24.593132Z","shell.execute_reply.started":"2023-05-01T03:36:24.585242Z","shell.execute_reply":"2023-05-01T03:36:24.592069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\n\n# function to build VGG model\ndef vgg_model():\n    # load model without classifier layers\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n    # mark loaded layers as not trainable\n    # for layer in base_model.layers:\n    #     layer.trainable = False\n    # add new classifier layers\n    flat1 = layers.Flatten()(base_model.layers[-1].output)\n    class1 = layers.Dense(1024, activation='relu')(flat1)\n    output = layers.Dense(num_class, activation='softmax')(class1)\n    # define new model\n    model = keras.Model(inputs=base_model.inputs, outputs=output)\n    return model    ","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:45:18.217684Z","iopub.execute_input":"2023-05-01T04:45:18.218620Z","iopub.status.idle":"2023-05-01T04:45:18.227258Z","shell.execute_reply.started":"2023-05-01T04:45:18.218565Z","shell.execute_reply":"2023-05-01T04:45:18.226229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Optimizer**","metadata":{"id":"sRji4y2-L67w"}},{"cell_type":"code","source":"def run_experiment(model,name):\n    optimizer = tfa.optimizers.AdamW(\n        learning_rate=learning_rate, weight_decay=weight_decay\n    )\n\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=[\n            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n            tfa.metrics.F1Score(num_classes=2)\n        ],\n    )\n\n    checkpoint_filepath = f\"/content/tmp/{name}/checkpoint\"\n    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n        checkpoint_filepath,\n        monitor=\"val_accuracy\",\n        save_best_only=True,\n        save_weights_only=True,\n    )\n\n    history = model.fit(\n        x=x_train,\n        y=y_train,\n        batch_size=batch_size,\n        epochs=15,\n        validation_data = (x_val,y_val),\n        callbacks=[checkpoint_callback],\n    )\n\n    model.load_weights(checkpoint_filepath)\n    _, accuracy, f1_score_res = model.evaluate(x_test, y_test)\n    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n    print(\"f1_score: \", f1_score_res)\n\n    return history","metadata":{"id":"jItvHjMcLI_6","execution":{"iopub.status.busy":"2023-05-01T03:26:24.099106Z","iopub.execute_input":"2023-05-01T03:26:24.099723Z","iopub.status.idle":"2023-05-01T03:26:24.107997Z","shell.execute_reply.started":"2023-05-01T03:26:24.099684Z","shell.execute_reply":"2023-05-01T03:26:24.106908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vit_classifier = vit_model() \n# vit_classifier.summary()\n# history = run_experiment(vit_classifier,\"vit\")","metadata":{"id":"jBtk29HEMGSJ","outputId":"73e42efe-24f2-412a-905c-91d8e9af1663","execution":{"iopub.status.busy":"2023-05-01T03:31:34.806100Z","iopub.execute_input":"2023-05-01T03:31:34.806884Z","iopub.status.idle":"2023-05-01T03:31:38.263409Z","shell.execute_reply.started":"2023-05-01T03:31:34.806841Z","shell.execute_reply":"2023-05-01T03:31:38.262385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_classifier = resnet_model()\n# resnet_classifier.summary()\nhistory = run_experiment(resnet_classifier, \"RESNET\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-01T03:38:27.960745Z","iopub.execute_input":"2023-05-01T03:38:27.961391Z","iopub.status.idle":"2023-05-01T03:40:34.717897Z","shell.execute_reply.started":"2023-05-01T03:38:27.961340Z","shell.execute_reply":"2023-05-01T03:40:34.716489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model = vgg_model()\n# vgg_model.summary()\nhistory = run_experiment(vgg_model, \"VGG\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:45:24.751879Z","iopub.execute_input":"2023-05-01T04:45:24.752287Z","iopub.status.idle":"2023-05-01T04:47:51.766476Z","shell.execute_reply.started":"2023-05-01T04:45:24.752248Z","shell.execute_reply":"2023-05-01T04:47:51.765434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"while 1:\n    continue","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:47:51.768664Z","iopub.execute_input":"2023-05-01T04:47:51.771827Z","iopub.status.idle":"2023-05-01T04:50:31.552241Z","shell.execute_reply.started":"2023-05-01T04:47:51.771786Z","shell.execute_reply":"2023-05-01T04:50:31.550563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='val')\nplt.legend()","metadata":{"id":"awp7i4vSfvPA","outputId":"6e8ebf62-b5f9-4450-d0ab-b85e2418d261","execution":{"iopub.status.busy":"2023-05-01T04:51:11.312867Z","iopub.execute_input":"2023-05-01T04:51:11.313594Z","iopub.status.idle":"2023-05-01T04:51:11.548510Z","shell.execute_reply.started":"2023-05-01T04:51:11.313553Z","shell.execute_reply":"2023-05-01T04:51:11.547524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='val')\nplt.legend()","metadata":{"id":"pw2vgqgDgWWe","outputId":"78f93ebb-abba-475f-d63c-decff649b134","execution":{"iopub.status.busy":"2023-05-01T04:51:24.415496Z","iopub.execute_input":"2023-05-01T04:51:24.416105Z","iopub.status.idle":"2023-05-01T04:51:24.652519Z","shell.execute_reply.started":"2023-05-01T04:51:24.416065Z","shell.execute_reply":"2023-05-01T04:51:24.651192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PLOT Prediction on Test Set","metadata":{}},{"cell_type":"code","source":"# use model to predict and plot the result\ny_pred = vgg_model.predict(x_test)\ny_pred = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\n\nprint(\"GROUND TRUTH: \")\nprint(f\"Label 1: \", np.count_nonzero(y_true == 1))\nprint(f\"Label 0: \", np.count_nonzero(y_true == 0))\n\n\nprint(\"PREDICTION: \")\nprint(f\"Label 1: \", np.count_nonzero(y_pred == 1))\nprint(f\"Label 0: \", np.count_nonzero(y_pred == 0))\n\n# plot random 20 x_test and their predicted labels and ground truth labels\nfig, axs = plt.subplots(4, 5, figsize=(15, 10))\nfor i in range(20):\n    ax = axs[i//5, i%5]\n    index = random.randint(0, len(x_test))\n    ax.imshow(x_test[index])\n    ax.set_title(f\"Predicted label: {y_pred[index]}\\nTrue label: {y_true[index]}\")\n    ax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:51:45.499050Z","iopub.execute_input":"2023-05-01T04:51:45.499973Z","iopub.status.idle":"2023-05-01T04:51:47.135783Z","shell.execute_reply.started":"2023-05-01T04:51:45.499919Z","shell.execute_reply":"2023-05-01T04:51:47.131554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}