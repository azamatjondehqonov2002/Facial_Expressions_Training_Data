{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-09T06:16:49.781026Z",
     "iopub.status.busy": "2023-08-09T06:16:49.780366Z",
     "iopub.status.idle": "2023-08-09T06:16:49.901181Z",
     "shell.execute_reply": "2023-08-09T06:16:49.900051Z",
     "shell.execute_reply.started": "2023-08-09T06:16:49.780981Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # plot\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "path = ('/kaggle/input/affectnet-training-data/')\n",
    "file = (path + 'labels.csv')\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:16:49.903556Z",
     "iopub.status.busy": "2023-08-09T06:16:49.903164Z",
     "iopub.status.idle": "2023-08-09T06:16:49.927462Z",
     "shell.execute_reply": "2023-08-09T06:16:49.926537Z",
     "shell.execute_reply.started": "2023-08-09T06:16:49.903529Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:16:49.929027Z",
     "iopub.status.busy": "2023-08-09T06:16:49.928645Z",
     "iopub.status.idle": "2023-08-09T06:16:49.939127Z",
     "shell.execute_reply": "2023-08-09T06:16:49.937982Z",
     "shell.execute_reply.started": "2023-08-09T06:16:49.928964Z"
    }
   },
   "outputs": [],
   "source": [
    "df.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:16:49.940844Z",
     "iopub.status.busy": "2023-08-09T06:16:49.940468Z",
     "iopub.status.idle": "2023-08-09T06:16:49.979924Z",
     "shell.execute_reply": "2023-08-09T06:16:49.978854Z",
     "shell.execute_reply.started": "2023-08-09T06:16:49.940812Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:16:49.982663Z",
     "iopub.status.busy": "2023-08-09T06:16:49.982315Z",
     "iopub.status.idle": "2023-08-09T06:16:49.989779Z",
     "shell.execute_reply": "2023-08-09T06:16:49.988266Z",
     "shell.execute_reply.started": "2023-08-09T06:16:49.982634Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Define an empty list\n",
    "file_counts = []\n",
    "def countFile(link):\n",
    "    path = link\n",
    "    num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
    "    file_counts.append(num_files)\n",
    "    print(f\"Number of files in directory {link} is \", num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:16:49.991654Z",
     "iopub.status.busy": "2023-08-09T06:16:49.991314Z",
     "iopub.status.idle": "2023-08-09T06:17:34.674077Z",
     "shell.execute_reply": "2023-08-09T06:17:34.672793Z",
     "shell.execute_reply.started": "2023-08-09T06:16:49.991626Z"
    }
   },
   "outputs": [],
   "source": [
    "countFile(\"/kaggle/input/affectnet-training-data/happy\")\n",
    "countFile(\"/kaggle/input/affectnet-training-data/sad\")\n",
    "countFile(\"/kaggle/input/affectnet-training-data/surprise\")\n",
    "countFile(\"/kaggle/input/affectnet-training-data/anger\")\n",
    "countFile(\"/kaggle/input/affectnet-training-data/disgust\")\n",
    "countFile(\"/kaggle/input/affectnet-training-data/contempt\")\n",
    "countFile(\"/kaggle/input/affectnet-training-data/fear\")\n",
    "countFile(\"/kaggle/input/affectnet-training-data/neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:17:34.677665Z",
     "iopub.status.busy": "2023-08-09T06:17:34.677308Z",
     "iopub.status.idle": "2023-08-09T06:17:35.028173Z",
     "shell.execute_reply": "2023-08-09T06:17:35.027064Z",
     "shell.execute_reply.started": "2023-08-09T06:17:34.677638Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "categories = ['happy', 'sad', 'surprise', 'anger', 'disgust', 'contempt', 'fear', 'neutral']\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(categories, file_counts, color='blue')\n",
    "plt.xlabel('Emotion Categories')\n",
    "plt.ylabel('Number of Files')\n",
    "plt.title('Number of Files in AffectNet Emotion Categories')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:17:35.030067Z",
     "iopub.status.busy": "2023-08-09T06:17:35.029691Z",
     "iopub.status.idle": "2023-08-09T06:17:37.149635Z",
     "shell.execute_reply": "2023-08-09T06:17:37.148511Z",
     "shell.execute_reply.started": "2023-08-09T06:17:35.030037Z"
    }
   },
   "outputs": [],
   "source": [
    "# display random images\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, sharey=True, constrained_layout=True, num=None, \n",
    "                        figsize=(5, 5), dpi=80, facecolor='gray', edgecolor='k')\n",
    "fig.suptitle(\"Sample Faces and Labels\")\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(8):\n",
    "    idx = random.randint(0, len(df)-1)  # randomly select an index\n",
    "    img_path = path + df['pth'][idx]\n",
    "    img = cv2.imread(img_path)  # read image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to BGR to RGB\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(df['label'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:17:37.151708Z",
     "iopub.status.busy": "2023-08-09T06:17:37.151251Z",
     "iopub.status.idle": "2023-08-09T06:17:37.159722Z",
     "shell.execute_reply": "2023-08-09T06:17:37.158598Z",
     "shell.execute_reply.started": "2023-08-09T06:17:37.151667Z"
    }
   },
   "outputs": [],
   "source": [
    "# how many emotions categories\n",
    "\n",
    "import os\n",
    "\n",
    "INPUT_PATH = \"/kaggle/input/affectnet-training-data/\"\n",
    "EMOTIONS = [f.name for f in os.scandir(INPUT_PATH) if f.is_dir()]\n",
    "IMAGE_SIZE = (96, 96)\n",
    "\n",
    "print(EMOTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:17:37.165253Z",
     "iopub.status.busy": "2023-08-09T06:17:37.164889Z",
     "iopub.status.idle": "2023-08-09T06:17:45.785751Z",
     "shell.execute_reply": "2023-08-09T06:17:45.784834Z",
     "shell.execute_reply.started": "2023-08-09T06:17:37.165225Z"
    }
   },
   "outputs": [],
   "source": [
    "# define functions to pre-process and load images into arrays\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "def image_generator(input_path, emotions, image_size):\n",
    "    for index, emotion in enumerate(emotions):\n",
    "        for filename in os.listdir(os.path.join(input_path, emotion)):\n",
    "            img = cv2.imread(os.path.join(input_path, emotion, filename))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            #img = cv2.resize(img, image_size)\n",
    "            #img = img.astype('float32') / 255.0  # Normilize\n",
    "            yield img, index\n",
    "\n",
    "def load_images(input_path, emotions, image_size):\n",
    "    X, y = [], []\n",
    "    for img, label in image_generator(input_path, emotions, image_size):\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "    X = np.array(X)\n",
    "    y = to_categorical(np.array(y))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:17:45.788813Z",
     "iopub.status.busy": "2023-08-09T06:17:45.788135Z",
     "iopub.status.idle": "2023-08-09T06:20:24.847056Z",
     "shell.execute_reply": "2023-08-09T06:20:24.845939Z",
     "shell.execute_reply.started": "2023-08-09T06:17:45.788782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the images\n",
    "X, y = load_images(INPUT_PATH, EMOTIONS, IMAGE_SIZE)\n",
    "input_shape = X[0].shape\n",
    "#input_shape = (96,96,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:20:24.849077Z",
     "iopub.status.busy": "2023-08-09T06:20:24.848700Z",
     "iopub.status.idle": "2023-08-09T06:20:25.083868Z",
     "shell.execute_reply": "2023-08-09T06:20:25.082621Z",
     "shell.execute_reply.started": "2023-08-09T06:20:24.849046Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# choose a random image index\n",
    "idx = np.random.randint(len(X))\n",
    "\n",
    "# display the image and its corresponding label from arrays\n",
    "plt.imshow(X[idx])\n",
    "plt.title(EMOTIONS[np.argmax(y[idx])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:20:25.086133Z",
     "iopub.status.busy": "2023-08-09T06:20:25.085463Z",
     "iopub.status.idle": "2023-08-09T06:20:26.445700Z",
     "shell.execute_reply": "2023-08-09T06:20:26.444469Z",
     "shell.execute_reply.started": "2023-08-09T06:20:25.086093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split pre-processed data\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:20:26.447452Z",
     "iopub.status.busy": "2023-08-09T06:20:26.447108Z",
     "iopub.status.idle": "2023-08-09T06:20:27.041472Z",
     "shell.execute_reply": "2023-08-09T06:20:27.040397Z",
     "shell.execute_reply.started": "2023-08-09T06:20:26.447422Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, BatchNormalization, Flatten, Dense, MaxPool2D\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Conv2D(32, (3,3), activation=\"selu\", input_shape=input_shape))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_4.add(Dropout(0.3))\n",
    "\n",
    "model_4.add(Conv2D(64, (3,3), activation=\"selu\"))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Conv2D(64, (3,3), activation=\"selu\"))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_4.add(Dropout(0.4))\n",
    "\n",
    "model_4.add(Conv2D(128, (3,3), activation=\"selu\"))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Conv2D(128, (3,3), activation=\"selu\"))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Conv2D(256, (3,3), activation=\"selu\"))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Conv2D(256, (3,3), activation=\"selu\"))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_4.add(Dropout(0.6))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(128, activation='selu', kernel_regularizer=l2(0.01)))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model_4.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T06:20:27.043518Z",
     "iopub.status.busy": "2023-08-09T06:20:27.043177Z",
     "iopub.status.idle": "2023-08-09T11:23:07.986004Z",
     "shell.execute_reply": "2023-08-09T11:23:07.984901Z",
     "shell.execute_reply.started": "2023-08-09T06:20:27.043488Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "history = model_4.fit(X_train, y_train, batch_size=128,\n",
    "                    epochs=30,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    \n",
    "                    callbacks = [EarlyStopping(patience=10, monitor='val_loss', mode='min'), \n",
    "                                 ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                   factor=0.5, \n",
    "                                                   patience=2, \n",
    "                                                   verbose=1),\n",
    "                                 ModelCheckpoint('best_model.h5', \n",
    "                                                 save_best_only=True, \n",
    "                                                 save_weights_only=True, \n",
    "                                                 monitor='val_accuracy', \n",
    "                                                 mode='max')],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:23:07.988155Z",
     "iopub.status.busy": "2023-08-09T11:23:07.987780Z",
     "iopub.status.idle": "2023-08-09T11:23:08.427893Z",
     "shell.execute_reply": "2023-08-09T11:23:08.426642Z",
     "shell.execute_reply.started": "2023-08-09T11:23:07.988125Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:55:04.589807Z",
     "iopub.status.busy": "2023-08-09T11:55:04.589386Z",
     "iopub.status.idle": "2023-08-09T11:55:05.466263Z",
     "shell.execute_reply": "2023-08-09T11:55:05.465441Z",
     "shell.execute_reply.started": "2023-08-09T11:55:04.589775Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n",
    "\n",
    "def Train_Val_Plot(acc,val_acc,loss,val_loss):\n",
    "    \n",
    "    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(acc) + 1), acc)\n",
    "    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
    "    ax1.set_title('History of Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    ax2.plot(range(1, len(loss) + 1), loss)\n",
    "    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax2.set_title('History of Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "Train_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n",
    "               history.history['loss'],history.history['val_loss'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:55:24.028336Z",
     "iopub.status.busy": "2023-08-09T11:55:24.027336Z",
     "iopub.status.idle": "2023-08-09T11:55:56.939695Z",
     "shell.execute_reply": "2023-08-09T11:55:56.938865Z",
     "shell.execute_reply.started": "2023-08-09T11:55:24.028298Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculates the false positive rate, true positive rate, and AUC score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_4.predict(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(8):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC AUC score\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "# Plot the ROC curves for each class and the micro-average ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "lw = 2\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], lw=lw, label='micro-average ROC curve (AUC = {0:0.2f})'\n",
    "                                                   ''.format(roc_auc[\"micro\"]))\n",
    "colors = ['cornflowerblue', 'darkorange', 'forestgreen', 'red', 'purple', 'gray', 'black', 'pink']\n",
    "for i, color in zip(range(8), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of {0} (AUC = {1:0.2f})'.format(EMOTIONS[i], roc_auc[i]))\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:56:54.247450Z",
     "iopub.status.busy": "2023-08-09T11:56:54.246577Z",
     "iopub.status.idle": "2023-08-09T11:57:35.287328Z",
     "shell.execute_reply": "2023-08-09T11:57:35.286016Z",
     "shell.execute_reply.started": "2023-08-09T11:56:54.247410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert one-hot encoded y_test back to integers\n",
    "y_test_int = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_4.predict(X_test)\n",
    "\n",
    "# Convert one-hot encoded y_pred back to integers\n",
    "y_pred_int = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test_int, y_pred_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T12:26:17.803166Z",
     "iopub.status.busy": "2023-08-09T12:26:17.802705Z",
     "iopub.status.idle": "2023-08-09T12:26:18.659176Z",
     "shell.execute_reply": "2023-08-09T12:26:18.657779Z",
     "shell.execute_reply.started": "2023-08-09T12:26:17.803130Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,accuracy_score,roc_curve,confusion_matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "cm=confusion_matrix(y_test_int, y_pred_int)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-09T11:23:09.120148Z",
     "iopub.status.idle": "2023-08-09T11:23:09.120945Z",
     "shell.execute_reply": "2023-08-09T11:23:09.120770Z",
     "shell.execute_reply.started": "2023-08-09T11:23:09.120749Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_4.save('/kaggle/working/model_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:57:56.548224Z",
     "iopub.status.busy": "2023-08-09T11:57:56.547791Z",
     "iopub.status.idle": "2023-08-09T11:58:07.479885Z",
     "shell.execute_reply": "2023-08-09T11:58:07.478342Z",
     "shell.execute_reply.started": "2023-08-09T11:57:56.548185Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:58:12.962236Z",
     "iopub.status.busy": "2023-08-09T11:58:12.961818Z",
     "iopub.status.idle": "2023-08-09T11:58:12.977186Z",
     "shell.execute_reply": "2023-08-09T11:58:12.975757Z",
     "shell.execute_reply.started": "2023-08-09T11:58:12.962206Z"
    }
   },
   "outputs": [],
   "source": [
    "# now let's modify our function to draw the emotion probability out of all 8 emotions\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "import cv2\n",
    "\n",
    "def detect_faces_emo(image_path, detection_confidence=0.99, min_face_size=10):\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Create an MTCNN detector instance\n",
    "    detector = MTCNN()\n",
    "\n",
    "    # Use the detector to detect faces in the image\n",
    "    faces = detector.detect_faces(image)\n",
    "\n",
    "    # Loop over the detected faces\n",
    "    for face in faces:\n",
    "        # Check the confidence score of the detection\n",
    "        if face['confidence'] < detection_confidence:\n",
    "            continue\n",
    "        # Extract the bounding box coordinates\n",
    "        x, y, width, height = face['box']\n",
    "        # Check the size of the bounding box\n",
    "        if min(width, height) < min_face_size:\n",
    "            continue\n",
    "        \n",
    "        # Extract the face region from the image\n",
    "        face_image = image[y:y+height, x:x+width]\n",
    "        # Resize the face image to 96x96\n",
    "        face_image_resized = cv2.resize(face_image, (96, 96))\n",
    "        # Reshape the face image to match the input shape of the model\n",
    "        face_image_reshaped = face_image_resized.reshape((1, 96, 96, 3))\n",
    "        # Use the model to predict the emotion of the face\n",
    "        predicted_emo = model_4.predict(face_image_reshaped)[0]\n",
    "        predicted_emo_sorted = sorted(list(enumerate(predicted_emo)), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Extract the predicted probabilities for each emotion category\n",
    "        # Extract the predicted probabilities for each emotion category\n",
    "        probabilities = [\"{}\".format(round(prob * 100)) for index, prob in predicted_emo_sorted]\n",
    "        \n",
    "        # Draw the predicted emotion label on the rectangle around the face\n",
    "        label = EMOTIONS[np.argmax(predicted_emo)]\n",
    "        cv2.putText(image, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1.8, (0, 255, 0), 3)\n",
    "        \n",
    "        # Draw a square rectangle around the face\n",
    "        face_size = min(width, height)\n",
    "        x_center = x + int(width / 2)\n",
    "        y_center = y + int(height / 2)\n",
    "        x1 = x_center - int(face_size / 2)\n",
    "        y1 = y_center - int(face_size / 2)\n",
    "        x2 = x_center + int(face_size / 2)\n",
    "        y2 = y_center + int(face_size / 2)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (127, 255, 0), 2)\n",
    "\n",
    "        # Draw a vertical table with the predicted emotion probabilities\n",
    "        table_x, table_y = x1, y2 + 20\n",
    "        for index, prob in predicted_emo_sorted:\n",
    "            table_y += 40\n",
    "            emotion = EMOTIONS[index]\n",
    "            cv2.putText(image, emotion, (table_x, table_y), cv2.FONT_HERSHEY_SIMPLEX, 1.6, (255, 255, 255), 3)\n",
    "            cv2.putText(image, \"{}%\".format(round(prob * 100)), (table_x + 250, table_y), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "    \n",
    "    # Save the image with the detected faces and predicted emotions to a file\n",
    "    cv2.imwrite(\"detected_faces.jpg\", image)\n",
    "\n",
    "    # Return the path to the saved file\n",
    "    return \"detected_faces.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T12:10:12.561389Z",
     "iopub.status.busy": "2023-08-09T12:10:12.560829Z",
     "iopub.status.idle": "2023-08-09T12:10:16.371317Z",
     "shell.execute_reply": "2023-08-09T12:10:16.369900Z",
     "shell.execute_reply.started": "2023-08-09T12:10:12.561352Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Detect faces in the new image of my friends and save the result to a file\n",
    "image_path = detect_faces_emo('/kaggle/input/caffe-model/face-detection-caffee-main/face-detection-caffee-main/media/sample9.jpg')\n",
    "# Display the saved image\n",
    "Image(filename=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:58:31.443360Z",
     "iopub.status.busy": "2023-08-09T11:58:31.442476Z",
     "iopub.status.idle": "2023-08-09T11:58:34.207263Z",
     "shell.execute_reply": "2023-08-09T11:58:34.206224Z",
     "shell.execute_reply.started": "2023-08-09T11:58:31.443326Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Detect faces in the new image of my friends and save the result to a file\n",
    "image_path = detect_faces_emo('/kaggle/input/caffe-model/face-detection-caffee-main/face-detection-caffee-main/media/sample2.jpg')\n",
    "# Display the saved image\n",
    "Image(filename=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:58:35.234381Z",
     "iopub.status.busy": "2023-08-09T11:58:35.233879Z",
     "iopub.status.idle": "2023-08-09T11:58:38.298875Z",
     "shell.execute_reply": "2023-08-09T11:58:38.297647Z",
     "shell.execute_reply.started": "2023-08-09T11:58:35.234343Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Detect faces in the new image of my friends and save the result to a file\n",
    "image_path = detect_faces_emo('/kaggle/input/caffe-model/face-detection-caffee-main/face-detection-caffee-main/media/sample3.jpg')\n",
    "# Display the saved image\n",
    "Image(filename=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:59:13.878661Z",
     "iopub.status.busy": "2023-08-09T11:59:13.878247Z",
     "iopub.status.idle": "2023-08-09T11:59:16.765327Z",
     "shell.execute_reply": "2023-08-09T11:59:16.764034Z",
     "shell.execute_reply.started": "2023-08-09T11:59:13.878629Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Detect faces in the new image of my friends and save the result to a file\n",
    "image_path = detect_faces_emo('/kaggle/input/caffe-model/face-detection-caffee-main/face-detection-caffee-main/media/sample4.jpg')\n",
    "# Display the saved image\n",
    "Image(filename=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T11:59:16.767862Z",
     "iopub.status.busy": "2023-08-09T11:59:16.767480Z",
     "iopub.status.idle": "2023-08-09T11:59:19.861288Z",
     "shell.execute_reply": "2023-08-09T11:59:19.860110Z",
     "shell.execute_reply.started": "2023-08-09T11:59:16.767829Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Detect faces in the new image of my friends and save the result to a file\n",
    "image_path = detect_faces_emo('/kaggle/input/caffe-model/face-detection-caffee-main/face-detection-caffee-main/media/sample5.jpg')\n",
    "# Display the saved image\n",
    "Image(filename=image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
